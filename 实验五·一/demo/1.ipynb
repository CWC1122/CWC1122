{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:20:17.588496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-07 03:20:17.588529: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/read_weights.py:28: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.uint8, np.uint16, np.object, np.bool]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39massert\u001b[39;00m tf\u001b[39m.\u001b[39m__version__\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m model_spec\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportFormat\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_model_maker/__init__.py:44\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Public APIs for TFLite Model Maker, a transfer learning library to train custom TFLite models.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mYou can install the package with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mhttps://www.tensorflow.org/lite/guide/model_maker.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_classifier\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_model_maker/audio_classifier/__init__.py:24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"APIs to train an audio classification model.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mTutorial:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mhttps://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/audio_classification_demo.py\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassifier\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m create\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/data_util/audio_dataloader.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m \u001b[39mimport\u001b[39;00m dataloader\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     29\u001b[0m error_import_librosa \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m image_spec\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector_spec\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/audio_spec.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m model_util\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_util.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m converter \u001b[39mas\u001b[39;00m tfjs_converter\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata \u001b[39mas\u001b[39;00m _metadata\n\u001b[1;32m     31\u001b[0m DEFAULT_SCALE, DEFAULT_ZERO_POINT \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m converters\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/converters/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports,line-too-long\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_h5_conversion\u001b[39;00m \u001b[39mimport\u001b[39;00m save_keras_model\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tfjs_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_model\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/converters/converter.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_h5_conversion \u001b[39mas\u001b[39;00m conversion\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tfjs_loader\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_saved_model_conversion_v2\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/converters/keras_h5_conversion.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m write_weights  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_weight_name\u001b[39m(weight_name):\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/write_weights.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m read_weights\n\u001b[1;32m     27\u001b[0m _OUTPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[1;32m     28\u001b[0m                   np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39mbool, np\u001b[39m.\u001b[39mobject]\n\u001b[1;32m     29\u001b[0m _AUTO_DTYPE_CONVERSION \u001b[39m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat16): np\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     31\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64): np\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     32\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mint64): np\u001b[39m.\u001b[39mint32,\n\u001b[1;32m     33\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mcomplex128): np\u001b[39m.\u001b[39mcomplex64}\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/read_weights.py:28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[1;32m     27\u001b[0m _INPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[0;32m---> 28\u001b[0m                  np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39;49mobject, np\u001b[39m.\u001b[39mbool]\n\u001b[1;32m     30\u001b[0m \u001b[39m# Number of bytes used to encode the length of a string in a string tensor.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m STRING_LENGTH_NUM_BYTES \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:26:04.163751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-07 03:26:04.163797: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libusb-1.0.so.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39massert\u001b[39;00m tf\u001b[39m.\u001b[39m__version__\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m model_spec\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportFormat\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_model_maker/__init__.py:44\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Public APIs for TFLite Model Maker, a transfer learning library to train custom TFLite models.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mYou can install the package with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mhttps://www.tensorflow.org/lite/guide/model_maker.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_classifier\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_model_maker/audio_classifier/__init__.py:24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"APIs to train an audio classification model.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mTutorial:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mhttps://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/audio_classification_demo.py\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassifier\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m create\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/data_util/audio_dataloader.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m \u001b[39mimport\u001b[39;00m dataloader\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     29\u001b[0m error_import_librosa \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m image_spec\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector_spec\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/audio_spec.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m model_util\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_util.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m converter \u001b[39mas\u001b[39;00m tfjs_converter\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata \u001b[39mas\u001b[39;00m _metadata\n\u001b[1;32m     31\u001b[0m DEFAULT_SCALE, DEFAULT_ZERO_POINT \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m     32\u001b[0m ESTIMITED_STEPS_PER_EPOCH \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_support/__init__.py:48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata_schema_py_generated\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mimport\u001b[39;00m schema_py_generated\n\u001b[0;32m---> 48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata_writers\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m platform\u001b[39m.\u001b[39msystem() \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mWindows\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     52\u001b[0m   \u001b[39m# Task Library is not supported on Windows yet.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_lite_support/metadata/python/metadata.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata_schema_py_generated \u001b[39mas\u001b[39;00m _metadata_fb\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m \u001b[39mimport\u001b[39;00m schema_py_generated \u001b[39mas\u001b[39;00m _schema_fb\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_metadata_version\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetadata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mflatbuffers_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_flatbuffers\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If exists, optionally use TensorFlow to open and check files. Used to\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   \u001b[39m# support more than local file systems.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m   \u001b[39m# In pip requirements, we doesn't necessarily need tensorflow as a dep.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: libusb-1.0.so.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2248716966.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    sudo apt update && sudo apt install libusb-1.0-0\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo apt update && sudo apt install libusb-1.0-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23\n",
      "  Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/read_weights.py:28: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.uint8, np.uint16, np.object, np.bool]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39massert\u001b[39;00m tf\u001b[39m.\u001b[39m__version__\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m model_spec\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportFormat\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_model_maker/__init__.py:44\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Public APIs for TFLite Model Maker, a transfer learning library to train custom TFLite models.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mYou can install the package with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mhttps://www.tensorflow.org/lite/guide/model_maker.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_classifier\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tflite_model_maker/audio_classifier/__init__.py:24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"APIs to train an audio classification model.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mTutorial:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mhttps://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/audio_classification_demo.py\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassifier\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m create\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/data_util/audio_dataloader.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m \u001b[39mimport\u001b[39;00m dataloader\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     29\u001b[0m error_import_librosa \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m image_spec\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector_spec\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/audio_spec.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m model_util\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_util.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m converter \u001b[39mas\u001b[39;00m tfjs_converter\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata \u001b[39mas\u001b[39;00m _metadata\n\u001b[1;32m     31\u001b[0m DEFAULT_SCALE, DEFAULT_ZERO_POINT \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m converters\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/converters/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports,line-too-long\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_h5_conversion\u001b[39;00m \u001b[39mimport\u001b[39;00m save_keras_model\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tfjs_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_model\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/converters/converter.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_h5_conversion \u001b[39mas\u001b[39;00m conversion\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tfjs_loader\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_saved_model_conversion_v2\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/converters/keras_h5_conversion.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m write_weights  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_weight_name\u001b[39m(weight_name):\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/write_weights.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m read_weights\n\u001b[1;32m     27\u001b[0m _OUTPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[1;32m     28\u001b[0m                   np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39mbool, np\u001b[39m.\u001b[39mobject]\n\u001b[1;32m     29\u001b[0m _AUTO_DTYPE_CONVERSION \u001b[39m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat16): np\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     31\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64): np\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     32\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mint64): np\u001b[39m.\u001b[39mint32,\n\u001b[1;32m     33\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mcomplex128): np\u001b[39m.\u001b[39mcomplex64}\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflowjs/read_weights.py:28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[1;32m     27\u001b[0m _INPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[0;32m---> 28\u001b[0m                  np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39;49mobject, np\u001b[39m.\u001b[39mbool]\n\u001b[1;32m     30\u001b[0m \u001b[39m# Number of bytes used to encode the length of a string in a string tensor.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m STRING_LENGTH_NUM_BYTES \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/tf/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:31:27.997528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-07 03:31:27.997582: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/tf/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 9s 0us/step\n",
      "228827136/228813984 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "image_path = tf.keras.utils.get_file(\n",
    "      'flower_photos.tgz',\n",
    "      'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "      extract=True)\n",
    "image_path = os.path.join(os.path.dirname(image_path), 'flower_photos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:32:22.379924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/envs/tf/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-06-07 03:32:22.379973: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-07 03:32:22.379999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-a1a9dc): /proc/driver/nvidia/version does not exist\n",
      "2023-06-07 03:32:22.392295: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 3670, num_label: 5, labels: daisy, dandelion, roses, sunflowers, tulips.\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader.from_folder(image_path)\n",
    "train_data, test_data = data.split(0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hub_keras_layer_v1v2 (HubKe  (None, 1280)             3413024   \n",
      " rasLayerV1V2)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,419,429\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 3,413,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:33:10.012193: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2023-06-07 03:33:10.360993: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2023-06-07 03:33:10.399226: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2023-06-07 03:33:10.434534: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25690112 exceeds 10% of free system memory.\n",
      "2023-06-07 03:33:10.447244: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154140672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 61s 566ms/step - loss: 0.8642 - accuracy: 0.7737\n",
      "Epoch 2/5\n",
      "103/103 [==============================] - 56s 538ms/step - loss: 0.6493 - accuracy: 0.8944\n",
      "Epoch 3/5\n",
      "103/103 [==============================] - 55s 532ms/step - loss: 0.6166 - accuracy: 0.9202\n",
      "Epoch 4/5\n",
      "103/103 [==============================] - 54s 518ms/step - loss: 0.5940 - accuracy: 0.9360\n",
      "Epoch 5/5\n",
      "103/103 [==============================] - 54s 518ms/step - loss: 0.5853 - accuracy: 0.9345\n"
     ]
    }
   ],
   "source": [
    "model = image_classifier.create(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 8s 469ms/step - loss: 0.6272 - accuracy: 0.9019\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:45:50.935762: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8op0oxei/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8op0oxei/assets\n",
      "2023-06-07 03:45:55.526983: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-07 03:45:55.527141: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-07 03:45:55.576969: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 913 nodes (656), 923 edges (664), time = 23.136ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.01ms.\n",
      "\n",
      "/opt/conda/envs/tf/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-06-07 03:45:56.749216: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-06-07 03:45:56.749273: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n",
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmpvwlfdplm/labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmpvwlfdplm/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir='.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
